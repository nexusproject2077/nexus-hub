"""
Version am√©lior√©e qui parse le HTML Instagram avec plusieurs patterns
"""
import requests
import os
import json
import time
import re

# Configuration
USERNAME = os.environ.get('INSTA_USERNAME', 'merickkn')
SESSION_ID = os.environ.get('INSTA_SESSION_ID', '')
OUTPUT_FILE = 'fils/followers_data.json'

def extract_followers_from_html(html_content):
    """Essaie plusieurs patterns pour extraire le nombre d'abonn√©s"""

    patterns = [
        # Pattern 1: Format JSON classique
        r'"edge_followed_by":\{"count":(\d+)\}',

        # Pattern 2: Format alternatif
        r'"follower_count":(\d+)',

        # Pattern 3: Dans les m√©tadonn√©es
        r'"followed_by":\{"count":(\d+)\}',

        # Pattern 4: Format r√©cent Instagram
        r'content="(\d+)\s+Followers"',

        # Pattern 5: Meta tag
        r'<meta\s+property="og:description"\s+content="[^"]*?(\d+)\s+Followers',

        # Pattern 6: SharedData
        r'"userInteractionCount":"(\d+)"',
    ]

    for i, pattern in enumerate(patterns, 1):
        match = re.search(pattern, html_content, re.IGNORECASE)
        if match:
            followers = int(match.group(1))
            print(f"   ‚úÖ Pattern {i} a trouv√©: {followers} abonn√©s")
            return followers

    return None

def fetch_followers():
    """R√©cup√®re le nombre d'abonn√©s Instagram"""

    # Donn√©es par d√©faut
    data = {
        "timestamp": int(time.time()),
        "followers": 0,
        "status": "initial_failure"
    }

    try:
        if not SESSION_ID:
            raise ValueError("INSTA_SESSION_ID n'est pas configur√©")

        print(f"üîç R√©cup√©ration des abonn√©s pour @{USERNAME}")
        print(f"üìù Session ID: {len(SESSION_ID)} caract√®res")

        # Headers pour simuler un navigateur (SANS Accept-Encoding pour √©viter compression)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }

        cookies = {
            'sessionid': SESSION_ID
        }

        # M√©thode 1: Scraping de la page publique
        print("\nüì° R√©cup√©ration de la page Instagram...")
        url = f'https://www.instagram.com/{USERNAME}/'

        response = requests.get(
            url,
            headers=headers,
            cookies=cookies,
            timeout=15,
            allow_redirects=True
        )

        print(f"   Status: {response.status_code}")
        print(f"   Encoding d√©tect√©: {response.encoding}")

        if response.status_code == 200:
            # S'assurer que le contenu est bien d√©cod√© en UTF-8
            response.encoding = response.apparent_encoding or 'utf-8'
            html_text = response.text

            print(f"   Taille HTML: {len(html_text)} caract√®res")
            print(f"   √âchantillon (premiers 200 caract√®res): {html_text[:200]}")

            # Essayer d'extraire avec plusieurs patterns
            followers = extract_followers_from_html(html_text)

            if followers is not None:
                print(f"   ‚úÖ SUCC√àS! Abonn√©s: {followers}")
                data['followers'] = followers
                data['status'] = 'success'
                return data
            else:
                print("   ‚ö†Ô∏è Aucun pattern n'a trouv√© le nombre d'abonn√©s")
                # Sauvegarder un √©chantillon du HTML pour debug
                print(f"   üìÑ √âchantillon HTML (500 premiers caract√®res):")
                print(response.text[:500])

        # Si √©chec
        print("\n‚ùå Impossible d'extraire le nombre d'abonn√©s")

        # Garder les anciennes donn√©es si disponibles
        try:
            with open(OUTPUT_FILE, 'r') as f:
                old_data = json.load(f)
                data['followers'] = old_data.get('followers', 0)
                data['status'] = f'failed_retaining_old_data (HTTP {response.status_code})'
                print(f"   üì¶ Conservation des anciennes donn√©es: {data['followers']} abonn√©s")
        except:
            data['status'] = f'failed_extraction (HTTP {response.status_code})'

    except requests.exceptions.Timeout:
        print("‚ùå Timeout - Instagram ne r√©pond pas")
        data['status'] = 'failed_timeout'

    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erreur r√©seau: {e}")
        data['status'] = f'failed_network: {type(e).__name__}'

    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        data['status'] = f'failed: {type(e).__name__}'

    finally:
        # Sauvegarder les donn√©es
        try:
            os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

            with open(OUTPUT_FILE, 'w') as f:
                json.dump(data, f, indent=4)

            print(f"\nüíæ Donn√©es sauvegard√©es: {OUTPUT_FILE}")
            print(f"   Status: {data['status']}")
            print(f"   Abonn√©s: {data['followers']}")

        except Exception as write_error:
            print(f"‚ùå Erreur d'√©criture: {write_error}")

    return data

if __name__ == "__main__":
    print("=" * 60)
    print("R√âCUP√âRATION DES ABONN√âS INSTAGRAM")
    print("=" * 60)

    result = fetch_followers()

    print("\n" + "=" * 60)
    if result['status'] == 'success':
        print(f"‚úÖ SUCC√àS! {result['followers']} abonn√©s")
    else:
        print(f"‚ùå √âCHEC: {result['status']}")
    print("=" * 60)
